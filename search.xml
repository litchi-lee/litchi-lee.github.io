<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>扩散模型的发展（简略版）</title>
      <link href="/2025/04/03/AIGC/overview_DM/"/>
      <url>/2025/04/03/AIGC/overview_DM/</url>
      
        <content type="html"><![CDATA[<p>其实契机是因为要完成高级机器学习的综述作业（@^@），这里也顺便写到博客里。</p><h1 id="引言">引言</h1><p>自监督学习是一种特殊的无监督学习，它不需要人工标注数据，而是通过数据本身构造学习任务。而作为自监督学习中的一个重要分支方向，图像生成模型已有几十年的持续发展，其核心目标是学习数据的概率分布<span class="math inline"><em>P</em>(<em>x</em>)</span>，并从中采样出新的数据分布以生成新的图像。</p><figure><imgsrc="https://raw.githubusercontent.com/litchi-lee/Images_shop/main/images/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B_0.png"alt="图像生成模型的发展大致历程" /><figcaption aria-hidden="true">图像生成模型的发展大致历程</figcaption></figure><h2 id="图像生成模型">图像生成模型</h2><p>目前主流的图像生成架构可大致分为三类：</p><ul><li><strong>基于自回归（Autoregressive）的模型</strong>，使用逐像素或逐子块的方式生成图像，每一步依赖于前面生成的部分，生成速度较慢并难以适应高分辨率生成任务；</li><li><strong>基于生成对抗网络（GANs）的方法</strong>，使用生成器和判别器组成的对抗网络生成图像，生成速度较快但训练不稳定，并且难以控制生成细节；</li><li><strong>基于扩散（Diffusion）模型的方法</strong>，在前向过程中逐步向图像添加噪声，并在反向过程中训练模型学习如何去噪，使得模型能从噪声中恢复出图像，从而生成新图像。基于扩散模型的方法生成质量高，训练稳定并能引入精确的条件控制，虽然早期存在采样速度缓慢的问题，但后期的各种改进版本使其能逐渐适应各种生成任务，特别是文生图（Text-to-Image）任务，基本统治了各大模型，包括OpenAI的DALL·E系列<sub><spanstyle="color:blue;"><span class="citation"data-cites="ramesh2022hierarchical">[@ramesh2022hierarchical]</span></span></sub>和Google的IMAGEN<sub><spanstyle="color:blue;"><span class="citation"data-cites="saharia2022photorealistic">[@saharia2022photorealistic]</span></span></sub>系列背后的核心技术都是扩散模型。</li></ul><h2 id="扩散模型的发展">扩散模型的发展</h2><p>其实扩散模型的提出最初是受到了非平衡统计物理（nonequilibriumthermodynamics）中的扩散过程的启发，后续经过一系列的改进和发展，逐渐成为最主流的生成模型之一。</p><p>近期的扩散理论基础可以追溯到去噪自编码器<sub><spanstyle="color:blue;"><span class="citation"data-cites="vincent2011connection">[@vincent2011connection]</span></span></sub>的提出，该工作证明了去噪过程与分数匹配的相关性，为之后宋飏等人提出基于分数匹配的生成模型（Score-BasedGenerative Models，SGM）<sub><span style="color:blue;"><spanclass="citation"data-cites="song2019generative">[@song2019generative]</span></span></sub>奠定了基础。之后，DDPM（DenoisingDiffusion Probabilistic Models）<sub><span style="color:blue;"><spanclass="citation"data-cites="ho2020denoising">[@ho2020denoising]</span></span></sub>作为现代扩散模型的开山之作，在DPM（DenoisingProbabilistic Models）<sub><span style="color:blue;"><spanclass="citation"data-cites="sohl2015deep">[@sohl2015deep]</span></span></sub>的基础上建立了从高斯噪声逐步去噪生成图像的框架。2021年宋飏等人提出的随机微分方程（StochasticDiffusion Equation，SDE）<sub><span style="color:blue;"><spanclass="citation"data-cites="song2020score">[@song2020score]</span></span></sub>则通过数学证明将基于分数匹配和基于去噪的生成模型的两种范式统一了起来，由此进一步巩固了扩散模型的理论基础。</p><p>但是此时的扩散模型有一个严重的问题，采样速度极慢，无法适应各大场景的需求，DDIM<sub><spanstyle="color:blue;"><span class="citation"data-cites="song2020denoising">[@song2020denoising]</span></span></sub>提出了非马尔科夫链推理的想法，将采样步骤大幅减少，显著提升推理速度，却仍能保持与DDPM不相上下的生成质量。后续分类器引导（Classifier-Guidance）<sub><spanstyle="color:blue;"><span class="citation"data-cites="dhariwal2021diffusion">[@dhariwal2021diffusion]</span></span></sub>和无分类器引导（Classifier-FreeGuidance）<sub><span style="color:blue;"><span class="citation"data-cites="ho2022classifier">[@ho2022classifier]</span></span></sub>的提出推动了条件扩散模型的发展，并通过大量实验证明扩散模型在图像生成任务上首次超越GAN。之后GLIDE<sub><spanstyle="color:blue;"><span class="citation"data-cites="nichol2021glide">[@nichol2021glide]</span></span></sub>和DALL·E2<sub><span style="color:blue;"><span class="citation"data-cites="ramesh2022hierarchical">[@ramesh2022hierarchical]</span></span></sub>尝试使用Clip来进行文本引导的扩散模型，实现了高质量的文本到图像的生成。</p><p>潜在扩散模型（Latent Diffusion Model，LDM）<sub><spanstyle="color:blue;"><span class="citation"data-cites="rombach2022high">[@rombach2022high]</span></span></sub>提出以潜在隐空间代替原像素空间以大幅减少计算量，成为之后StableDiffusion的技术核心，支持高效的文本到图像生成。DiT（DiffusionTransformer）<sub><span style="color:blue;"><span class="citation"data-cites="peebles2023scalable">[@peebles2023scalable]</span></span></sub>则将原UNet结构替换为了纯Transformer架构，尽管计算量有所增加，但能适应更高分辨率的图像生成任务。除此之外，VideoDiffusion<sub><span style="color:blue;"><span class="citation"data-cites="ho2022video">[@ho2022video]</span></span></sub>等工作则探索了3DDiffusion的可能，Consistency Models<sub><span style="color:blue;"><spanclass="citation"data-cites="song2023consistency">[@song2023consistency]</span></span></sub>则尝试进一步加快采样速度的极限。</p><h1 id="相关工作">相关工作</h1><p>本节将根据扩散模型的发展介绍部分重要的相关工作。</p><h2 id="ncsn">NCSN</h2><p>首先本文将介绍宋飏老师的基于分数匹配的生成模型（Score-basedGenerative Model，SGM）的工作，原论文这个工作又叫作Noise ConditionalScore Networks（NCSN）<sub><span style="color:blue;"><spanclass="citation"data-cites="song2019generative">[@song2019generative]</span></span></sub>。NCSN通过估计数据分布的梯度，实现从噪声到数据的生成。</p><p>具体来说，假设有一个数据分布 <spanclass="math inline"><em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>(<em>x</em>)</span>，我们需要估计该数据分布的对数梯度，又定义为<strong>分数函数</strong>（ScoreFuction）。但是直接估计数据分布的梯度很难，NCSN引入了多个噪声尺度来进行分数估计，类似于DDPM中加噪过程中的时间步，即：</p><p><span class="math display">$$  \begin{split}    s_\theta(x)\approx\nabla_x\log p_\mathrm{data}(x|\sigma)  \end{split}$$</span></p><p>由此可以得到分数匹配的目标函数为：</p><p><span class="math display">$$\begin{gather}\begin{split}    J(\theta) &amp;=\frac{1}{2}\intp_\mathrm{data}{(x)}\|s_{data}(x)-s_\theta(x)\|_2^2dx \\     &amp;=\frac{1}{2}\mathbb{E}_{p_{\mathrm{data}}(x)}\left[\left\|s_{data}(x)-s_\theta(x)\right\|_2^2\right]\end{split}\end{gather}$$</span></p><p>但是在实际求解时，<spanclass="math inline"><em>s</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>(<em>x</em>)</span>是无法计算的。经过一系列变换，可以得到原目标函数的一个等价表示：</p><p><span class="math display">$$\begin{gather}\begin{split}    J(\theta) &amp;=\int p_{\text {data}}(x)\left[\operatorname{tr}\left(\nabla_xs_\theta(x)\right)+\frac{1}{2}\left\|s_\theta(x)\right\|_2^2\right] dx\\    &amp;=\mathbb{E}_{p_{\text {data}}(x)}\left[\operatorname{tr}\left(\nabla_xs_\theta(x)\right)+\frac{1}{2}\left\|s_\theta(x)\right\|_2^2\right]\end{split}\end{gather}$$</span></p><p>其中涉及到了二阶偏导的计算，这在网络层次很深的时候开销是很大的，因此NCSN提出了分层分数匹配和降噪分数匹配两种方法来解决这个问题。分数估计训练完成后，便可以使用<strong>郎之万动力学（LangevinDynamics，LD）采样</strong>来生成数据分布：</p><p><span class="math display">$$    x_{t+1}=x_t+\frac{\sigma}{2}s_\theta(x_t)+\sqrt{\sigma}z_t$$</span></p><p>其中 <span class="math inline"><em>z</em><sub><em>t</em></sub></span>表示高斯噪声，这个过程模拟的是粒子在数据分布的梯度场中进行随机行走，最终收敛到真实数据分布。NCSN可以看作是扩散模型的前身，后续宋飏老师提出的SDE也从数学形式上统一了DDPM和NCSN，虽然它的采样较慢，训练也不稳定，但是它为后续扩散模型的发展提供了坚实的理论基础。</p><h2 id="ddpm">DDPM</h2><p>去噪扩散概率模型（Denoising Diffusion ProbabilisticModels）<sub><span style="color:blue;"><span class="citation"data-cites="ho2020denoising">[@ho2020denoising]</span></span></sub>是现代扩散模型的开山之作，它正式确立了扩散模型的数学框架，在图像生成任务上表现很出色。它的核心思想是前向扩散（ForwardDiffusion）和逆向去噪（ReverseDenoising）两部分，其推导基于马尔科夫链进行逐步加噪和去噪。</p><figure><imgsrc="https://raw.githubusercontent.com/litchi-lee/Images_shop/main/images/DDPM_0.png"alt="DDPM的扩散及去噪过程" /><figcaption aria-hidden="true">DDPM的扩散及去噪过程</figcaption></figure><h3 id="前向扩散">前向扩散</h3><p>首先对于前向扩散过程，给定真实数据 <spanclass="math inline"><em>x</em><sub>0</sub> ∼ <em>q</em>(<em>x</em>)</span>，经过 <span class="math inline"><em>T</em></span>步的加噪过程，数据最终符合标准高斯分布。定义单步扩散过程为：</p><p><span class="math display">$$    q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)$$</span></p><p>令 <spanclass="math inline"><em>α</em><sub><em>t</em></sub> = 1 − <em>β</em><sub><em>t</em></sub></span>，由此可以发现 <spanclass="math inline"><em>q</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub><em>t</em> − 1</sub>)</span>就是一个以 <span class="math inline">$\sqrt{\alpha_t}x_{t-1}$</span>为均值，以 <spanclass="math inline">(1 − <em>α</em><sub><em>t</em></sub>)<em>I</em></span>为方差的高斯分布，加噪过程相当于是 <spanclass="math inline">$\sqrt{\alpha_t}x_{t-1}$</span> 基础上加上一个 <spanclass="math inline">𝒩(0, (1 − <em>α</em><sub><em>t</em></sub>)<em>I</em>)</span>的随机高斯噪声。进一步推导可以得到直接从 <spanclass="math inline"><em>x</em><sub>0</sub></span> 生成 <spanclass="math inline"><em>x</em><sub><em>t</em></sub></span>的公式为：</p><p><span class="math display">$$    q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)$$</span></p><p>其中 <spanclass="math inline">$\bar{\alpha}_t=\prod_{i=1}^t\alpha_i$</span>，表示累积噪声。最终当 <spanclass="math inline"><em>t</em> → <em>T</em></span> 时，<spanclass="math inline"><em>x</em><sub><em>T</em></sub></span>近似服从于标准高斯分布 <spanclass="math inline">𝒩(0, <em>I</em>)</span>。</p><h3 id="逆向去噪">逆向去噪</h3><p>逆向去噪的目标是从 <spanclass="math inline"><em>x</em><sub><em>T</em></sub></span>开始，逐步去噪恢复 <spanclass="math inline"><em>x</em><sub>0</sub></span> ，即 <spanclass="math inline">$p(x_{0:T})=p(x_T)\prod_{t=T-1}^0p(x_t|x_{t+1})$</span>，那么问题的关键在于如何求解 <spanclass="math inline"><em>p</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub><em>t</em> + 1</sub>)</span>。假设我们可以训练一个模型求解这个分布：</p><p><span class="math display">$$\begin{split}    p_{\theta}(x_{t-1} \mid x_t)=\mathcal{N}(x_{t-1} ; \mu_{\theta}(x_t,t),  \Sigma_{\theta}(x_t, t))\end{split}$$</span></p><p>不同于DPM<sub><span style="color:blue;"><span class="citation"data-cites="sohl2015deep">[@sohl2015deep]</span></span></sub>的直接预测<span class="math inline"><em>x</em><sub>0</sub></span>，DDPM使用UNet预测每一个时间步添加的噪声 <spanclass="math inline">$\hat{\epsilon_\theta}(x_t,t)\approx\epsilon$</span>，然后通过一系列数学推导得到：</p><p><span class="math display">$$\begin{split}    \mu_\theta\left(x_t,t\right)=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\hat{\epsilon}_\theta\left(x_t, t\right)\right)\end{split}$$</span></p><p><spanclass="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em> − 1</sub> ∣ <em>x</em><sub><em>t</em></sub>)</span>的预测均值已经得到，而预测方差 <spanclass="math inline"><em>Σ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>, <em>t</em>)</span>在DDPM中被设为随机高斯噪声 <spanclass="math inline"><em>σ</em><sub><em>t</em></sub><em>z</em></span>，由此可以得到：</p><p><span class="math display">$$\begin{split}    x_{t-1}=\mu_\theta\left(x_t, t\right)+\sigma_t z\end{split}$$</span></p><p>可以看到，模型预测每一步的噪声 <spanclass="math inline"><em>ϵ</em><sub><em>t</em></sub></span>要比之前直接预测 <span class="math inline"><em>x</em><sub>0</sub></span>容易得多，DDPM的最终目标函数就是最小化去噪误差，即：</p><p><span class="math display">$$\begin{split}    \mathcalL(\theta)=\mathbb{E}_{x_0,\epsilon\sim\mathcal{N}(0,I),t}\left[\left\|\epsilon-\hat{\epsilon}_\theta(x_t,t)\right\|^2\right]\end{split}$$</span></p><p>这个损失函数就相当于训练模型预测噪声 <spanclass="math inline"><em>ϵ</em></span>的均方误差，学习难度大幅降低。不仅如此，在ImageNet256$$256任务上，DDPM取得了优于GAN的FID分数，这是扩散模型首次取得能和GAN竞争的分数，后续OpenAI发布了基于DDPM的DALL·E，也进一步提升了扩散模型的影响力。</p><h2 id="sde">SDE</h2><p>随机微分方程（Stochastic Differential Equations，SDE）<sub><spanstyle="color:blue;"><span class="citation"data-cites="song2020score">[@song2020score]</span></span></sub>是宋飏老师提出的一个连续时间扩散框架，它从数学上统一了NCSN和DDPM。如前文所介绍的，NCSN采用分数匹配的方法来预测概率分布的对数梯度，之后使用郎之万动力学采样以生成图像，它可以看作是连续噪声扰动；而DDPM则在有限的<span class="math inline"><em>T</em></span>步内加噪随后逆向去噪，采用预测噪声的方法来生成数据分布，基础理论依据是离散马尔可夫过程。</p><p><strong>随机微分方程</strong>是一类在经典微分方程基础上引入随机过程的数学方程，用于描述具有随机性或不确定性系统的演化，数据的随机扩散过程就可以用随机微分方程进行描述：</p><p><span class="math display">$$\begin{split}    dx=f(x,t)dt+g(t)dW\end{split}$$</span></p><p>其中 <spanclass="math inline"><em>f</em>(<em>x</em>, <em>t</em>)</span>是漂移项（drift term），用于描述数据的确定性过程，<spanclass="math inline"><em>g</em>(<em>t</em>)</span>是扩散项（diffusionterm），描述系统的随机性过程，<spanclass="math inline"><em>d</em><em>W</em></span>是标准布朗运动（WienerProcess）。经过一系列数学推导，可以分别得到NCSN和DDPM所对应的SDE，分别命名为<strong>VE-SDE</strong>（VarianceExploding SDE）和<strong>VP-SDE</strong>（Variance PreservingSDE）：</p><p><span class="math display">$$\begin{gather}\begin{split}        dx&amp;=\sqrt{d[\sigma^2(t)]}dW\quad\text{(VESDE)} \\        dx&amp;=-\frac{1}{2}\beta(t)xdt+\sqrt{\beta(t)}dW\quad\text{(VPSDE)}\end{split}\end{gather}$$</span></p><p>可以发现VESDE没有漂移项，噪声会随着 <spanclass="math inline"><em>t</em></span>的增加而爆炸性增长，因此叫作”VarianceExploding”，而VPSDE的噪声变化则较为平缓，因此叫作”VariancePreserving”。其实除了这两种方程外，原文还针对VPSDE提出了改进版本sub-VPSDE，为扩散项加上了一个额外的衰减因子让噪声水平增长得更慢，不会在早期就过度加噪，造成采样时需要更多的去噪步数。</p><p>使用SDE采样的关键是要确定逆向SDE，即从 <spanclass="math inline"><em>x</em><sub><em>T</em></sub></span> 逆推 <spanclass="math inline"><em>x</em><sub>0</sub></span>，由于扩散过程的反向过程也是一个扩散过程，因此我们可以得到逆向SDE的方程，其中的漂移系数和扩散系数和SDE保持一致：</p><p><span class="math display">$$\begin{split}    dx=[f(x,t)-g^2(t)\nabla_x\log p_t(x)]dt+g(t)d\bar{W}\end{split}$$</span></p><p>其中 <spanclass="math inline">∇<sub><em>x</em></sub>log <em>p</em><sub><em>t</em></sub>(<em>x</em>)</span>可由神经网络 <spanclass="math inline"><em>s</em><sub><em>θ</em></sub>(<em>x</em>, <em>t</em>)</span>预测得到，由此可以分别得到两个方程的逆向SDE离散表达：</p><p><span class="math display">$$\begin{gather}\begin{split}    x_i&amp;=x_{i+1}+(\sigma_{i+1}^2-\sigma_i^2)s_{\theta^*}(x_{i+1},i+1)+\sqrt{\sigma_{i+1}^2-\sigma_i^2}z_{i+1}\quad\text{(VESDE)} \\    x_i&amp;=(2-\sqrt{1-\beta_{i+1}})x_{i+1}+\beta_{i+1}s_{\theta^*}(x_{i+1},i+1)+\sqrt{\beta_{i+1}}z_{i+1}\quad\text{(VPSDE)}\end{split}\end{gather}$$</span></p><p>根据两个逆向SDE可以发现，它们的形式分别等效于NCSN所使用的郎之万采样和DDPM所使用的马尔科夫链，由此原文使用连续的SDE统一了两种生成框架。</p><p>除此之外，原文还提出了<strong>PC采样方法</strong>，这也是SDE数值求解常用的一种方法，因为SDE是对时间连续的方程，所以不同的离散化方案总是存在一定误差，可以使用score-basedMCMC采样方法进行进一步校正，即在每一步采样中额外添加一个修正步骤，让数据更快收敛。这里PC采样采用的修正器还是郎之万动力学方程，总结来说PC采样分两步：（1）Predictor，使用逆向SDE进行一步采样；（2）Corrector，使用郎之万动力学采样进一步调整。</p><p>去掉逆向SDE中的随机项（布朗运动 <spanclass="math inline"><em>d</em><em>w</em></span>项）后，可以得到概率流常微分方程（Probabilistic FlowODE），此时整个采样过程是一条确定性的轨迹，求解更快，因此适用于高效采样需求的任务。</p><h2 id="ddim">DDIM</h2><p>DDPM中，前向扩散过程定义为马尔科夫过程，为数据 <spanclass="math inline"><em>x</em><sub>0</sub></span>逐步添加噪声，逆向过程同样需要逐步去噪。但是为了保证最终前向过程的 <spanclass="math inline"><em>x</em><sub><em>T</em></sub></span>满足高斯噪声，这里的步数 <span class="math inline"><em>T</em></span>要设置得足够大（1000+），导致逆向过程的采样步数也非常大，推理的时间和计算开销巨大。DDIM<sub><spanstyle="color:blue;"><span class="citation"data-cites="song2020denoising">[@song2020denoising]</span></span></sub>提出了确定性采样方法，是扩散过程变为确定性过程（ODE），从而加速采样。</p><p>首先回顾一下定义在马尔科夫链的DDPM中单步加噪和单步去噪过程：</p><p><span class="math display">$$\begin{gather}\begin{split}        x_t &amp;= \sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t \\        x_{t-1}&amp;=\frac{1}{\alpha_t}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha_t}}}\epsilon_\theta(x_t,t))+\sigma_tz\end{split}\end{gather}$$</span></p><p>基于此重新推导DDPM的优化目标，可以得到：</p><p><span class="math display">$$\begin{split}\mathcalL=\mathbb{E}_{x_0,\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})}\left[\|\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon,t\right)\|^2\right]\end{split}$$</span></p><p>可以发现，DDPM的优化目标其实仅仅依赖于边缘分布 <spanclass="math inline"><em>q</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub>0</sub>)</span>，而不依赖于联合分布 <spanclass="math inline"><em>q</em>(<em>x</em><sub>1 : <em>T</em></sub>|<em>x</em><sub>0</sub>)</span>，因此可以看出DDPM其实并不要求推理过程一定要是马尔科夫过程，只要推理分布满足边缘分布条件即可。经过一系列重新推导，可以得到非马尔科夫链下的单步逆向过程为：</p><p><span class="math display">$$\begin{split}\mathbf{x}_{t-1}=\sqrt{\alpha_{t-1}}\left(\underbrace{\frac{\mathbf{x}_t-\sqrt{1-\alpha_t}\epsilon_\theta(\mathbf{x}_t,t)}{\sqrt{\alpha_t}}}_{\mathrm{predicted~}\mathbf{x}_0}\right)+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2}\cdot\epsilon_\theta(\mathbf{x}_t,t)}_{\text{directionpointing to }\mathbf{x}_t}+\underbrace{\sigma_t\epsilon_t}_{\text{randomnoise}}\end{split}$$</span></p><p>其中 <spanclass="math inline">$\sigma_t^2=\eta\cdot\sqrt{(1-\alpha_{t-1})/(1-\alpha_t)}\sqrt{(1-\alpha_t/\alpha_{t-1})}$</span>。</p><ul><li>当 <span class="math inline"><em>η</em> = 1</span>时，此时的生成过程和DDPM一致；</li><li>当 <span class="math inline"><em>η</em> = 0</span>时，此时的生成过程就没有随机噪声项了，是一个确定性的过程，这就是DDIM（DenoisingDiffusion ImplicModel），此时的样本生成就变成了确定的过程，有点类似于SDE中的概率流ODE。</li></ul><figure><imgsrc="https://raw.githubusercontent.com/litchi-lee/Images_shop/main/images/DDIM_0.png"alt="DDIM的采样过程" /><figcaption aria-hidden="true">DDIM的采样过程</figcaption></figure><p>由于DDIM并没有明确前向过程，这意味这可以定义一个更短的步数的前向过程以减少采样步数。原文从原始序列<span class="math inline">[1, …, <em>T</em>]</span> 采样一个长度为 <spanclass="math inline"><em>S</em></span> 的子序列 <spanclass="math inline">[<em>τ</em><sub>1</sub>, …, <em>τ</em><sub><em>S</em></sub>]</span>，此时前向过程 <spanclass="math inline">[<em>x</em><sub><em>τ</em><sub>1</sub></sub>, …, <em>x</em><sub><em>τ</em><sub><em>S</em></sub></sub>]</span>同样还是马尔科夫链，并且满足 <spanclass="math inline">$q({x}_{\tau_i}|{x}_0)=\mathcal{N}({x}_t;\sqrt{\alpha_{\tau_i}}{x}_0,(1-\alpha_{\tau_i}){I})$</span>。由此该生成过程也可以用这个子序列的反向马尔科夫链来替代，最终加速生成过程，能从DDPM的1000步采样减少为50步采样，大幅降低推理开销。</p><h2 id="cdm">CDM</h2><p>条件扩散模型（Conditional DiffusionModel，CDM）指使用条件控制生成的扩散模型，其中最常用的方法是引导（guidance）方法，可以用于增强生成质量或是让模型朝向某个目标分布进行采样。最主要的两种方法是：分类器引导（ClassifierGuidance）<sub><span style="color:blue;"><span class="citation"data-cites="dhariwal2021diffusion">[@dhariwal2021diffusion]</span></span></sub>和无分类器引导（Classifier-FreeGuidance）<sub><span style="color:blue;"><span class="citation"data-cites="ho2022classifier">[@ho2022classifier]</span></span></sub>，因此这里将分别简要介绍这两篇工作。</p><h3 id="分类器引导">分类器引导</h3><p>假设我们需要在扩散过程中引入条件信息 <spanclass="math inline"><em>y</em></span>，直觉上来说，条件信息不会影响前向过程，因为最终加噪都会变为高斯噪音，即<spanclass="math inline"><em>q</em>(<em>x</em><sub>1 : <em>T</em></sub>|<em>x</em><sub>0</sub>, <em>y</em>) = <em>q</em>(<em>x</em><sub>1 : <em>T</em></sub>|<em>x</em><sub>0</sub>)</span>。因此我们需要重点关注逆向过程的条件控制，不妨说我们需要重点关注分数函数<spanclass="math inline"><em>ŝ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>, <em>t</em>) ≈ ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>)</span>的变化。引入条件信息后，我们可以使用贝叶斯公式进行几步变换：</p><p><span class="math display">$$\begin{gather}\begin{split}        \nabla_{x_t}\logp(x_t|y)&amp;=\nabla_{x_t}\log(\frac{p(x_t)p(y|x_t)}{p(y)}) \\        &amp;= \nabla_{x_t}\log p(x_t)+\nabla_{x_t}\logp(y|x_t)-\nabla_{x_t}\log p(y) \\        &amp;= \nabla_{x_t}\log p(x_t)+\nabla_{x_t}\log p(y|x_t)\end{split}\end{gather}$$</span></p><p>可以看到，展开后有两项，其中第一项相当于无条件生成时的分数函数，可以称为无条件分数（UnconditionalScore）；而第二项相当于一个分类器的对数梯度，称为对抗梯度（AdversarialGradient）。为了能更好的控制生成内容的方向，论文额外引入了一个超参数<span class="math inline"><em>λ</em></span> 作为引导强度：</p><p><span class="math display">$$\begin{gather}\nabla_{x_t}\log p(x_t|y)=\nabla_{x_t}\logp(x_t)+\lambda\nabla_{x_t}\log p(y|x_t)\end{gather}$$</span></p><h3 id="无分类器引导">无分类器引导</h3><p>自OpenAI发布分类器引导的条件生成范式后，GoogleBrain团队提出了无分类器引导方法，直接在扩散模型内部学习引导信息，无需额外的分类器。还是从分数估计的角度来进行推导，从条件引导的工作我们得知<spanclass="math inline">∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>|<em>y</em>) = ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>) + ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>y</em>|<em>x</em><sub><em>t</em></sub>)</span>，变换一下可以得到 <spanclass="math inline">∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>y</em>|<em>x</em><sub><em>t</em></sub>) = ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>|<em>y</em>) − ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>)</span>，由此可以得到：</p><p><span class="math display">$$\begin{gather}\begin{split}    \nabla_{x_t}\log p(x_t|y)&amp;=\nabla_{x_t}\logp(x_t)+\lambda\nabla_{x_t}\log p(y|x_t) \\    &amp;=\nabla_{x_t}\log p(x_t)+\lambda(\nabla_{x_t}\logp(x_t|y)-\nabla_{x_t}\log p(x_t)) \\    &amp;=\lambda\nabla_{x_t}\log p(x_t|y)+(1-\lambda)\log p(x_t)\end{split}\end{gather}$$</span></p><p>可以发现，此时分数仍然分为两部分：第一项可以看作是条件分数（ConditionalScore），第二项则是无条件分数（Unconditional Score）。并且 <spanclass="math inline"><em>λ</em></span> 的取值会影响到条件控制的强弱：</p><ul><li>当 <span class="math inline"><em>λ</em> = 0</span>时，此时相当于无条件生成；</li><li>当 <span class="math inline"><em>λ</em> &gt; 1</span>时，模型会优先考虑条件控制而远离无条件分数网络方向。</li></ul><p>这样看似乎还是要训练两个网络，但实际上无条件可看作是条件控制的特殊情况，即<span class="math inline"><em>y</em> = ⌀</span>，这样在训练时可以交替训练有条件和无条件的情况。</p><h2 id="ldm">LDM</h2><p>DDPM生成的图像质量已经非常好了，但是训练开销很大，一个问题在于中间的加噪状态<span class="math inline"><em>x</em><sub><em>t</em></sub></span>的尺寸是和输入保持一致的，这使得其训练开销随图像分辨率的增大而加重，无法适应高质量图像生成任务。因此潜在扩散模型（LatentDiffusion Model，LDM）<sub><span style="color:blue;"><spanclass="citation"data-cites="rombach2022high">[@rombach2022high]</span></span></sub>针对这个问题做了一些改进，<strong>将图像从像素空间表示（PixelSpace）转变为潜在空间表示（LatentSpace）实现高分辨率图像生成任务</strong>。</p><figure><imgsrc="https://raw.githubusercontent.com/litchi-lee/Images_shop/main/images/LDM_0.png"alt="潜在扩散模型的模型架构" /><figcaption aria-hidden="true">潜在扩散模型的模型架构</figcaption></figure><p>LDM的主要架构由三部分组成：VAE编码器（Encoder）、扩散模型以及VAE解码器（Decoder）。其中VAE编码器将高维图像<span class="math inline"><em>x</em><sub>0</sub></span>编码表示为潜在表示 <spanclass="math inline"><em>z</em><sub>0</sub></span>，然后送入扩散模型中进行扩散和去噪，最终VAE解码器将去噪得到的潜在空间表示<span class="math inline">$\hat{z_0}$</span> 还原为像素空间表示 <spanclass="math inline">$\hat{x_0}$</span>，得到高质量的图像。这个VAE可以是预训练好的模型，在训练扩散模型时，其参数是被冻结的。</p><p>而对于条件生成处理上，LDM引入条件融合模块 <spanclass="math inline"><em>τ</em><sub><em>θ</em></sub></span>来处理多种模态的条件信息 <span class="math inline"><em>y</em></span>。比如对于文生图任务，这里的 <spanclass="math inline"><em>τ</em><sub><em>θ</em></sub></span>就是一个文本编码器，可以使用预训练好的CLIP模型<sub><spanstyle="color:blue;"><span class="citation"data-cites="radford2021learning">[@radford2021learning]</span></span></sub>中的文本编码器。同时引入条件融合开关：</p><ul><li>对于文本输入，这里在Unet网络中添加了Attention层将Embedding向量 <spanclass="math inline"><em>τ</em><sub><em>θ</em></sub>(<em>y</em>)</span>融合到每层特征中；</li><li>而对于其他空间的条件（语义图、修复图等），则直接通过拼接完成条件融合。</li></ul><p>由此我们可以得到LDM的目标函数为：</p><p><span class="math display">$$\begin{split}\mathcal L_{L D M}:=\mathbb{E}_{\mathcal{E}(x), y, \epsilon \sim\mathcal{N}(0,1), t}\left[\left\|\epsilon-\epsilon_\theta\left(z_t, t,\tau_\theta(y)\right)\right\|_2^2\right]\end{split}$$</span></p><p>后续爆火的StableDiffusion就是LDM的一个开源预训练模型，一度占据图像生成开源领域的主导地位。</p><h2 id="dit">DiT</h2><p>DiT（Diffusion Transformer）<sub><span style="color:blue;"><spanclass="citation"data-cites="peebles2023scalable">[@peebles2023scalable]</span></span></sub>是MetaAI提出的基于Transformer的扩散模型，它首次在扩散模型完全用Transformer替代了UNet，提升了扩散模型的可扩展性和生成质量。</p><figure><imgsrc="https://raw.githubusercontent.com/litchi-lee/Images_shop/main/images/DiT_0.png"alt="DiT的模型架构" /><figcaption aria-hidden="true">DiT的模型架构</figcaption></figure><p>DiT也是一个作用在潜在空间上的模型，同样使用一个VQVAE将图像编码到潜在空间上，之后送入DiT模块中加工。不同的是，由于舍弃掉了CNN，这里使用了ViT进一步将潜在空间特征转换为一维序列特征（PatchToken），并将时间步 <span class="math inline"><em>t</em></span>和条件信息 <span class="math inline"><em>y</em></span>融合后嵌入到图像的Patch Token中。</p><p>为了选择融合条件特征效果最好的DiT模块，原文一共探索了四种不同的DiT模块：</p><ul><li>基于上下文条件（In-contextconditioning）的DiT模块，直接将条件特征嵌入到输入序列中；</li><li>基于交叉注意力（Cross Attention）的DiT模块，将时间步 <spanclass="math inline"><em>t</em></span> 和条件信息 <spanclass="math inline"><em>y</em></span>拼成长度为2的序列，然后输入到多头交叉注意力模块中和图像特征进行融合；</li><li>基于自适应层归一化（Adaptive LayerNormalization，AdaLN）的DiT模块，通过使用条件信息学习 <spanclass="math inline"><em>β</em></span> 和 <spanclass="math inline"><em>γ</em></span>两个归一化参数来调整中间特征；</li><li>基于Zero初始化的AdaLN的DiT模块，是AdaLN方案的改进版本，将AdaLN的线性层参数初始化为zero，并额外在每个残差模块结束之前引入回归缩放参数<span class="math inline"><em>α</em></span> 。</li></ul><p>通过对四种模块进行对比实验，发现AdaLN-Zero的效果是最好的，DiT模块默认采用这种方式来嵌入条件。</p><p>同时，需要注意的是DiT所使用的扩散模型沿用了OpenAI的改进版DDPM<sub><spanstyle="color:blue;"><span class="citation"data-cites="song2020improved">[@song2020improved]</span></span></sub>，不再采用固定的方差，而是采用另一个网络来预测方差<spanclass="math inline"><em>Σ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>, <em>t</em>) = exp (<em>v</em>log <em>β</em><sub><em>t</em></sub> + (1 − <em>v</em>)<em>β̃</em><sub><em>t</em></sub>)</span>，训练时采用无分类器引导的范式进行学习。该种方法对于视频生成等需要强可扩展性的任务来说很适用，OpenAI推出的Sora就是用了DiT作为模型架构。</p><h2 id="pixart">PixArt</h2><p>在DiT推出之后，华为诺亚方舟实验室又提出了PixArt-<spanclass="math inline"><em>α</em></span><sub><spanstyle="color:blue;"><span class="citation"data-cites="chen2023pixart">[@chen2023pixart]</span></span></sub>，这也是一种基于transformer的文本到图像的扩散模型，它在显著降低训练成本的同时，也实现了很不错的图像生成质量。</p><p>PixArt-<spanclass="math inline"><em>α</em></span>模型还是使用DiT作为基础架构，但是进行了一些改进。原DiT架构中的每个DiT模块中的<spanclass="math inline"><em>S</em><sup><em>i</em></sup></span>都是通过独立的MLP计算得到的，即<spanclass="math inline"><em>S</em><sup>(<em>i</em>)</sup> = <em>f</em><sup>(<em>i</em>)</sup>(<em>c</em> + <em>t</em>)</span>，其中 <span class="math inline"><em>c</em>, <em>t</em></span>分别表示类别条件和时间步信息，这会占据很高的开销。基于此，PixArt提出了AdaLN-single，定义一个全局<span class="math inline"><em>S̄</em> = <em>f</em>(<em>t</em>)</span>，只使用时间步信息生成 <span class="math inline"><em>S̄</em></span>，在第 <span class="math inline"><em>i</em></span> 个模块中，通过计算<spanclass="math inline"><em>S</em><sup>(<em>i</em>)</sup> = <em>g</em>(<em>S̄</em>, <em>E</em><sup>(<em>i</em>)</sup>)</span>得到每个模块的缩放和偏移参数，其中 <spanclass="math inline"><em>E</em><sup>(<em>i</em>)</sup></span>是可训练的嵌入表示；而文本条件 <spanclass="math inline"><em>c</em></span>则通过一个额外的多头交叉注意力嵌入到模块中。大量实验表明，通过引入全局MLP和逐层嵌入处理时间步<span class="math inline"><em>t</em></span>信息、使用交叉注意力层处理文本信息 <spanclass="math inline"><em>c</em></span>的改进，能在有效减小模型大小的同时保持原生成能力。</p><figure><imgsrc="https://raw.githubusercontent.com/litchi-lee/Images_shop/main/images/PixArt_0.png"alt="PixArt-\alpha的模型架构" /><figcaption aria-hidden="true">PixArt-<spanclass="math inline"><em>α</em></span>的模型架构</figcaption></figure><p>除此之外，PixArt-<spanclass="math inline"><em>α</em></span>将复杂的文本到图像的生成任务分解为三个子任务以逐步训练：</p><ul><li>像素级依赖的学习（Pixel DependencyLearning），为了实现后续高质量的生成，PixArt先在ImageNet上预训练类引导生成模型，这一过程成本低廉并能帮助模型有效学习到图像的像素级依赖性；</li><li>文本到图像的精确对齐学习（Text-image AlignmentLearning），原论文构建了一个包含高概念密度的精确文本-图像对数据集，相较于以往的数据集，歧义显著减少，并能处理更多的名词；</li><li>高质量图像微调（High-resolution and Aesthetic ImageGeneration），为了生成高审美质量的图片，原论文最后使用高质量的图片对模型进行进一步微调。</li></ul><h1 id="总结与展望">总结与展望</h1><p>在扩散模型成为主流之前，基于能量的生成模型和分数匹配已经被研究了许多年，这些工作为扩散模型的出现奠定了理论基础，直到后来DDPM的提出正式标志着扩散模型的爆发。之后一系列的工作探讨了对原始模型的改进，体现在加速采样、降低训练开销、提升图像生成质量等，一度使扩散模型超越基于自回归和GAN的生成模型成为大规模生成任务的首选模型。后来进入大模型时代，包括DALL·E、IMAGEN、StableDiffusion的文生图大模型更是进一步引爆了Diffusion的影响力。总的来说，作为当下Aigc领域中热门研究领域之一，扩散模型的发展正值草长莺飞的时期，它开创了一种全新的生成模型范式，并被广泛应用于各类生成式任务以及当下视觉生成大模型中。</p><p>未来对于扩散模型的研究还在继续，比如如何进一步提升采样速度、创造更通用的多模态扩散模型、更精细的条件控制、量化优化以实现EdgeAI等等，还有很多课题值得探索...</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AIGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/03/31/hello-world/"/>
      <url>/2025/03/31/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><div class="note warning simple"><p>需要先<code>hexo g</code>，再<code>hexo s</code></p></div><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
