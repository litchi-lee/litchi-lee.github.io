<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>扩散模型的发展（简略版） | Leo的博客</title><meta name="author" content="Leo Sinclair"><meta name="copyright" content="Leo Sinclair"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="关于学习DM的一些记录（待补充！）">
<meta property="og:type" content="article">
<meta property="og:title" content="扩散模型的发展（简略版）">
<meta property="og:url" content="https://litchi-lee.github.io/2025/03/28/AIGC/overview_DM/index.html">
<meta property="og:site_name" content="Leo的博客">
<meta property="og:description" content="关于学习DM的一些记录（待补充！）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg7.jpg">
<meta property="article:published_time" content="2025-03-27T16:00:00.000Z">
<meta property="article:modified_time" content="2025-05-08T08:41:58.222Z">
<meta property="article:author" content="Leo Sinclair">
<meta property="article:tag" content="AIGC">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg7.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "扩散模型的发展（简略版）",
  "url": "https://litchi-lee.github.io/2025/03/28/AIGC/overview_DM/",
  "image": "https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg7.jpg",
  "datePublished": "2025-03-27T16:00:00.000Z",
  "dateModified": "2025-05-08T08:41:58.222Z",
  "author": [
    {
      "@type": "Person",
      "name": "Leo Sinclair",
      "url": "https://litchi-lee.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://litchi-lee.github.io/2025/03/28/AIGC/overview_DM/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: Leo Sinclair","link":"链接: ","source":"来源: Leo的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '扩散模型的发展（简略版）',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(img/bg0.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/img0.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/galleries/"><i class="fa-fw fas fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 听歌日志</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/img2.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/logo0.jpg" alt="Logo"><span class="site-name">Leo的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">扩散模型的发展（简略版）</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/galleries/"><i class="fa-fw fas fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 听歌日志</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">扩散模型的发展（简略版）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-27T16:00:00.000Z" title="发表于 2025-03-28 00:00:00">2025-03-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-08T08:41:58.222Z" title="更新于 2025-05-08 16:41:58">2025-05-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p><strong>系列文章：</strong></p>
<ol class="series-items"><li><a href="/2025/03/28/AIGC/overview_DM/" title="扩散模型的发展（简略版）">扩散模型的发展（简略版）</a></li><li><a href="/2025/04/15/AIGC/DDPM/" title="DDPM总结">DDPM总结</a></li><li><a href="/2025/04/17/AIGC/DDIM/" title="DDIM总结">DDIM总结</a></li><li><a href="/2025/04/27/AIGC/LDM/" title="LDM的细节">LDM的细节</a></li><li><a href="/2025/05/08/AIGC/DIT/" title="DiT的细节">DiT的细节</a></li><li><a href="/2025/05/08/AIGC/iDDPM/" title="iDDPM总结">iDDPM总结</a></li></ol>
<p>其实契机是因为要完成高级机器学习的综述作业（@^@），这里也顺便写到博客里。</p>
<h1 id="引言">引言</h1>
<p>自监督学习是一种特殊的无监督学习，它不需要人工标注数据，而是通过数据本身构造学习任务。而作为自监督学习中的一个重要分支方向，图像生成模型已有几十年的持续发展，其核心目标是学习数据的概率分布 <span class="math inline"><em>P</em>(<em>x</em>)</span> ，并从中采样出新的数据分布以生成新的图像。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B_0.png" alt="" /><figcaption>图像生成模型的发展大致历程</figcaption>
</figure>
<h2 id="图像生成模型">图像生成模型</h2>
<p>目前主流的图像生成架构可大致分为三类：</p>
<ul>
<li><strong>基于自回归（Autoregressive）的模型</strong>，使用逐像素或逐子块的方式生成图像，每一步依赖于前面生成的部分，生成速度较慢并难以适应高分辨率生成任务；</li>
<li><strong>基于生成对抗网络（GANs）的方法</strong>，使用生成器和判别器组成的对抗网络生成图像，生成速度较快但训练不稳定，并且难以控制生成细节；</li>
<li><strong>基于扩散（Diffusion）模型的方法</strong>，在前向过程中逐步向图像添加噪声，并在反向过程中训练模型学习如何去噪，使得模型能从噪声中恢复出图像，从而生成新图像。基于扩散模型的方法生成质量高，训练稳定并能引入精确的条件控制，虽然早期存在采样速度缓慢的问题，但后期的各种改进版本使其能逐渐适应各种生成任务，特别是文生图（Text-to-Image）任务，基本统治了各大模型，包括OpenAI的DALL·E系列<sub><span style="color:blue;"><span class="citation" data-cites="ramesh2022hierarchical">[@ramesh2022hierarchical]</span></span></sub>和Google的IMAGEN<sub><span style="color:blue;"><span class="citation" data-cites="saharia2022photorealistic">[@saharia2022photorealistic]</span></span></sub>系列背后的核心技术都是扩散模型。</li>
</ul>
<h2 id="扩散模型的发展">扩散模型的发展</h2>
<p>其实扩散模型的提出最初是受到了非平衡统计物理（nonequilibrium thermodynamics）中的扩散过程的启发，后续经过一系列的改进和发展，逐渐成为最主流的生成模型之一。</p>
<p>近期的扩散理论基础可以追溯到去噪自编码器<sub><span style="color:blue;"><span class="citation" data-cites="vincent2011connection">[@vincent2011connection]</span></span></sub>的提出，该工作证明了去噪过程与分数匹配的相关性，为之后宋飏等人提出基于分数匹配的生成模型（Score-Based Generative Models，SGM）<sub><span style="color:blue;"><span class="citation" data-cites="song2019generative">[@song2019generative]</span></span></sub>奠定了基础。之后，DDPM（Denoising Diffusion Probabilistic Models）<sub><span style="color:blue;"><span class="citation" data-cites="ho2020denoising">[@ho2020denoising]</span></span></sub>作为现代扩散模型的开山之作，在DPM（Denoising Probabilistic Models）<sub><span style="color:blue;"><span class="citation" data-cites="sohl2015deep">[@sohl2015deep]</span></span></sub>的基础上建立了从高斯噪声逐步去噪生成图像的框架。2021年宋飏等人提出的随机微分方程（Stochastic Diffusion Equation，SDE）<sub><span style="color:blue;"><span class="citation" data-cites="song2020score">[@song2020score]</span></span></sub>则通过数学证明将基于分数匹配和基于去噪的生成模型的两种范式统一了起来，由此进一步巩固了扩散模型的理论基础。</p>
<p>但是此时的扩散模型有一个严重的问题，采样速度极慢，无法适应各大场景的需求，DDIM<sub><span style="color:blue;"><span class="citation" data-cites="song2020denoising">[@song2020denoising]</span></span></sub>提出了非马尔科夫链推理的想法，将采样步骤大幅减少，显著提升推理速度，却仍能保持与DDPM不相上下的生成质量。后续分类器引导（Classifier-Guidance）<sub><span style="color:blue;"><span class="citation" data-cites="dhariwal2021diffusion">[@dhariwal2021diffusion]</span></span></sub>和无分类器引导（Classifier-Free Guidance）<sub><span style="color:blue;"><span class="citation" data-cites="ho2022classifier">[@ho2022classifier]</span></span></sub>的提出推动了条件扩散模型的发展，并通过大量实验证明扩散模型在图像生成任务上首次超越GAN。之后GLIDE<sub><span style="color:blue;"><span class="citation" data-cites="nichol2021glide">[@nichol2021glide]</span></span></sub>和DALL·E 2<sub><span style="color:blue;"><span class="citation" data-cites="ramesh2022hierarchical">[@ramesh2022hierarchical]</span></span></sub>尝试使用Clip来进行文本引导的扩散模型，实现了高质量的文本到图像的生成。</p>
<p>潜在扩散模型（Latent Diffusion Model，LDM）<sub><span style="color:blue;"><span class="citation" data-cites="rombach2022high">[@rombach2022high]</span></span></sub>提出以潜在隐空间代替原像素空间以大幅减少计算量，成为之后Stable Diffusion的技术核心，支持高效的文本到图像生成。DiT（Diffusion Transformer）<sub><span style="color:blue;"><span class="citation" data-cites="peebles2023scalable">[@peebles2023scalable]</span></span></sub>则将原UNet结构替换为了纯Transformer架构，尽管计算量有所增加，但能适应更高分辨率的图像生成任务。除此之外，Video Diffusion<sub><span style="color:blue;"><span class="citation" data-cites="ho2022video">[@ho2022video]</span></span></sub>等工作则探索了3D Diffusion的可能，Consistency Models<sub><span style="color:blue;"><span class="citation" data-cites="song2023consistency">[@song2023consistency]</span></span></sub>则尝试进一步加快采样速度的极限。</p>
<h1 id="相关工作">相关工作</h1>
<p>本节将根据扩散模型的发展介绍部分重要的相关工作。</p>
<h2 id="ncsn">NCSN</h2>
<p>首先本文将介绍宋飏老师的基于分数匹配的生成模型（Score-based Generative Model，SGM）的工作，原论文这个工作又叫作Noise Conditional Score Networks（NCSN）<sub><span style="color:blue;"><span class="citation" data-cites="song2019generative">[@song2019generative]</span></span></sub>。NCSN通过估计数据分布的梯度，实现从噪声到数据的生成。</p>
<p>具体来说，假设有一个数据分布 <span class="math inline"><em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>(<em>x</em>)</span> ，我们需要估计该数据分布的对数梯度，又定义为<strong>分数函数</strong>（Score Fuction）。但是直接估计数据分布的梯度很难，NCSN引入了多个噪声尺度来进行分数估计，类似于DDPM中加噪过程中的时间步，即：</p>
<p><span class="math display">$$
  \begin{split} 
    s_\theta(x)\approx\nabla_x\log p_\mathrm{data}(x|\sigma) 
  \end{split}
$$</span></p>
<p>由此可以得到分数匹配的目标函数为：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
    J(\theta) &amp;=\frac{1}{2}\int p_\mathrm{data}{(x)}\|s_{data}(x)-s_\theta(x)\|_2^2dx \\
     &amp;=\frac{1}{2}\mathbb{E}_{p_{\mathrm{data}}(x)}\left[\left\|s_{data}(x)-s_\theta(x)\right\|_2^2\right]
\end{split}
\end{gather}
$$</span></p>
<p>但是在实际求解时，<span class="math inline"><em>s</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub>(<em>x</em>)</span> 是无法计算的。经过一系列变换，可以得到原目标函数的一个等价表示：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
    J(\theta) &amp;=\int p_{\text {data }}(x)\left[\operatorname{tr}\left(\nabla_x s_\theta(x)\right)+\frac{1}{2}\left\|s_\theta(x)\right\|_2^2\right] dx \\
    &amp;=\mathbb{E}_{p_{\text {data }}(x)}\left[\operatorname{tr}\left(\nabla_x s_\theta(x)\right)+\frac{1}{2}\left\|s_\theta(x)\right\|_2^2\right]
\end{split}
\end{gather}
$$</span></p>
<p>其中涉及到了二阶偏导的计算，这在网络层次很深的时候开销是很大的，因此NCSN提出了分层分数匹配和降噪分数匹配两种方法来解决这个问题。分数估计训练完成后，便可以使用<strong>郎之万动力学（Langevin Dynamics，LD）采样</strong>来生成数据分布：</p>
<p><span class="math display">$$ 
    x_{t+1}=x_t+\frac{\sigma}{2}s_\theta(x_t)+\sqrt{\sigma}z_t 
$$</span></p>
<p>其中 <span class="math inline"><em>z</em><sub><em>t</em></sub></span> 表示高斯噪声，这个过程模拟的是粒子在数据分布的梯度场中进行随机行走，最终收敛到真实数据分布。NCSN可以看作是扩散模型的前身，后续宋飏老师提出的SDE也从数学形式上统一了DDPM和NCSN，虽然它的采样较慢，训练也不稳定，但是它为后续扩散模型的发展提供了坚实的理论基础。</p>
<h2 id="ddpm">DDPM</h2>
<p>去噪扩散概率模型（Denoising Diffusion Probabilistic Models）<sub><span style="color:blue;"><span class="citation" data-cites="ho2020denoising">[@ho2020denoising]</span></span></sub>是现代扩散模型的开山之作，它正式确立了扩散模型的数学框架，在图像生成任务上表现很出色。它的核心思想是前向扩散（Forward Diffusion）和逆向去噪（Reverse Denoising）两部分，其推导基于马尔科夫链进行逐步加噪和去噪。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/DDPM_0.png" alt="" /><figcaption>DDPM的扩散及去噪过程</figcaption>
</figure>
<h3 id="前向扩散">前向扩散</h3>
<p>首先对于前向扩散过程，给定真实数据 <span class="math inline"><em>x</em><sub>0</sub> ∼ <em>q</em>(<em>x</em>)</span> ，经过 <span class="math inline"><em>T</em></span> 步的加噪过程，数据最终符合标准高斯分布。定义单步扩散过程为：</p>
<p><span class="math display">$$
    q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)
$$</span></p>
<p>令 <span class="math inline"><em>α</em><sub><em>t</em></sub> = 1 − <em>β</em><sub><em>t</em></sub></span> ，由此可以发现 <span class="math inline"><em>q</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub><em>t</em> − 1</sub>)</span> 就是一个以 <span class="math inline">$\sqrt{\alpha_t}x_{t-1}$</span> 为均值，以 <span class="math inline">(1 − <em>α</em><sub><em>t</em></sub>)<em>I</em></span> 为方差的高斯分布，加噪过程相当于是 <span class="math inline">$\sqrt{\alpha_t}x_{t-1}$</span> 基础上加上一个 <span class="math inline">𝒩(0, (1 − <em>α</em><sub><em>t</em></sub>)<em>I</em>)</span> 的随机高斯噪声。进一步推导可以得到直接从 <span class="math inline"><em>x</em><sub>0</sub></span> 生成 <span class="math inline"><em>x</em><sub><em>t</em></sub></span> 的公式为：</p>
<p><span class="math display">$$
    q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)
$$</span></p>
<p>其中 <span class="math inline">$\bar{\alpha}_t=\prod_{i=1}^t\alpha_i$</span> ，表示累积噪声。最终当 <span class="math inline"><em>t</em> → <em>T</em></span> 时，<span class="math inline"><em>x</em><sub><em>T</em></sub></span> 近似服从于标准高斯分布 <span class="math inline">𝒩(0, <em>I</em>)</span>。</p>
<h3 id="逆向去噪">逆向去噪</h3>
<p>逆向去噪的目标是从 <span class="math inline"><em>x</em><sub><em>T</em></sub></span> 开始，逐步去噪恢复 <span class="math inline"><em>x</em><sub>0</sub></span> ，即 <span class="math inline">$p(x_{0:T})=p(x_T)\prod_{t=T-1}^0p(x_t|x_{t+1})$</span> ，那么问题的关键在于如何求解 <span class="math inline"><em>p</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub><em>t</em> + 1</sub>)</span> 。假设我们可以训练一个模型求解这个分布：</p>
<p><span class="math display">$$
\begin{split}
    p_{\theta}(x_{t-1} \mid x_t)=\mathcal{N}(x_{t-1} ; \mu_{\theta}(x_t, t),  \Sigma_{\theta}(x_t, t))
\end{split}
$$</span></p>
<p>不同于DPM<sub><span style="color:blue;"><span class="citation" data-cites="sohl2015deep">[@sohl2015deep]</span></span></sub>的直接预测 <span class="math inline"><em>x</em><sub>0</sub></span> ，DDPM使用UNet预测每一个时间步添加的噪声 <span class="math inline">$\hat{\epsilon_\theta}(x_t,t)\approx\epsilon$</span> ，然后通过一系列数学推导得到：</p>
<p><span class="math display">$$
\begin{split}
    \mu_\theta\left(x_t, t\right)=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \hat{\epsilon}_\theta\left(x_t, t\right)\right)
\end{split}
$$</span></p>
<p><span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em> − 1</sub>∣<em>x</em><sub><em>t</em></sub>)</span> 的预测均值已经得到，而预测方差 <span class="math inline"><em>Σ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>)</span> 在DDPM中被设为随机高斯噪声 <span class="math inline"><em>σ</em><sub><em>t</em></sub><em>z</em></span> ，由此可以得到：</p>
<p><span class="math display">$$
\begin{split}
    x_{t-1}=\mu_\theta\left(x_t, t\right)+\sigma_t z
\end{split}
$$</span></p>
<p>可以看到，模型预测每一步的噪声 <span class="math inline"><em>ϵ</em><sub><em>t</em></sub></span> 要比之前直接预测 <span class="math inline"><em>x</em><sub>0</sub></span> 容易得多，DDPM的最终目标函数就是最小化去噪误差，即：</p>
<p><span class="math display">$$
\begin{split}
    \mathcal L(\theta)=\mathbb{E}_{x_0,\epsilon\sim\mathcal{N}(0,I),t}\left[\left\|\epsilon-\hat{\epsilon}_\theta(x_t,t)\right\|^2\right]
\end{split}
$$</span></p>
<p>这个损失函数就相当于训练模型预测噪声 <span class="math inline"><em>ϵ</em></span> 的均方误差，学习难度大幅降低。不仅如此，在ImageNet 256$$256任务上，DDPM取得了优于GAN的FID分数，这是扩散模型首次取得能和GAN竞争的分数，后续OpenAI发布了基于DDPM的DALL·E，也进一步提升了扩散模型的影响力。</p>
<h2 id="sde">SDE</h2>
<p>随机微分方程（Stochastic Differential Equations，SDE）<sub><span style="color:blue;"><span class="citation" data-cites="song2020score">[@song2020score]</span></span></sub>是宋飏老师提出的一个连续时间扩散框架，它从数学上统一了NCSN和DDPM。如前文所介绍的，NCSN采用分数匹配的方法来预测概率分布的对数梯度，之后使用郎之万动力学采样以生成图像，它可以看作是连续噪声扰动；而DDPM则在有限的 <span class="math inline"><em>T</em></span> 步内加噪随后逆向去噪，采用预测噪声的方法来生成数据分布，基础理论依据是离散马尔可夫过程。</p>
<p><strong>随机微分方程</strong>是一类在经典微分方程基础上引入随机过程的数学方程，用于描述具有随机性或不确定性系统的演化，数据的随机扩散过程就可以用随机微分方程进行描述：</p>
<p><span class="math display">$$
\begin{split}
    dx=f(x,t)dt+g(t)dW
\end{split}
$$</span></p>
<p>其中 <span class="math inline"><em>f</em>(<em>x</em>, <em>t</em>)</span> 是漂移项（drift term），用于描述数据的确定性过程，<span class="math inline"><em>g</em>(<em>t</em>)</span>是扩散项（diffusion term），描述系统的随机性过程，<span class="math inline"><em>d</em><em>W</em></span>是标准布朗运动（Wiener Process）。经过一系列数学推导，可以分别得到NCSN和DDPM所对应的SDE，分别命名为 <strong>VE-SDE</strong>（Variance Exploding SDE）和 <strong>VP-SDE</strong>（Variance Preserving SDE）：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
        dx&amp;=\sqrt{d[\sigma^2(t)]}dW\quad\text{(VESDE)} \\
        dx&amp;=-\frac{1}{2}\beta(t)xdt+\sqrt{\beta(t)}dW\quad\text{(VPSDE)} 
\end{split}
\end{gather}
$$</span></p>
<p>可以发现VESDE没有漂移项，噪声会随着 <span class="math inline"><em>t</em></span> 的增加而爆炸性增长，因此叫作“Variance Exploding”，而VPSDE的噪声变化则较为平缓，因此叫作“Variance Preserving”。其实除了这两种方程外，原文还针对VPSDE提出了改进版本sub-VPSDE，为扩散项加上了一个额外的衰减因子让噪声水平增长得更慢，不会在早期就过度加噪，造成采样时需要更多的去噪步数。</p>
<p>使用SDE采样的关键是要确定逆向SDE，即从 <span class="math inline"><em>x</em><sub><em>T</em></sub></span> 逆推 <span class="math inline"><em>x</em><sub>0</sub></span>，由于扩散过程的反向过程也是一个扩散过程，因此我们可以得到逆向SDE的方程，其中的漂移系数和扩散系数和SDE保持一致：</p>
<p><span class="math display">$$
\begin{split}
    dx=[f(x,t)-g^2(t)\nabla_x\log p_t(x)]dt+g(t)d\bar{W}
\end{split}
$$</span></p>
<p>其中 <span class="math inline">∇<sub><em>x</em></sub>log <em>p</em><sub><em>t</em></sub>(<em>x</em>)</span> 可由神经网络 <span class="math inline"><em>s</em><sub><em>θ</em></sub>(<em>x</em>, <em>t</em>)</span> 预测得到，由此可以分别得到两个方程的逆向SDE离散表达：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
    x_i&amp;=x_{i+1}+(\sigma_{i+1}^2-\sigma_i^2)s_{\theta^*}(x_{i+1},i+1) +\sqrt{\sigma_{i+1}^2-\sigma_i^2}z_{i+1}\quad\text{(VESDE)} \\
    x_i&amp;=(2-\sqrt{1-\beta_{i+1}})x_{i+1}+\beta_{i+1}s_{\theta^*}(x_{i+1},i+1)+\sqrt{\beta_{i+1}}z_{i+1}\quad\text{(VPSDE)} 
\end{split}
\end{gather}
$$</span></p>
<p>根据两个逆向SDE可以发现，它们的形式分别等效于NCSN所使用的郎之万采样和DDPM所使用的马尔科夫链，由此原文使用连续的SDE统一了两种生成框架。</p>
<p>除此之外，原文还提出了<strong>PC采样方法</strong>，这也是SDE数值求解常用的一种方法，因为SDE是对时间连续的方程，所以不同的离散化方案总是存在一定误差，可以使用score-based MCMC采样方法进行进一步校正，即在每一步采样中额外添加一个修正步骤，让数据更快收敛。这里PC采样采用的修正器还是郎之万动力学方程，总结来说PC采样分两步：（1）Predictor，使用逆向SDE进行一步采样；（2）Corrector，使用郎之万动力学采样进一步调整。</p>
<p>去掉逆向SDE中的随机项（布朗运动 <span class="math inline"><em>d</em><em>w</em></span> 项）后，可以得到概率流常微分方程（Probabilistic Flow ODE），此时整个采样过程是一条确定性的轨迹，求解更快，因此适用于高效采样需求的任务。</p>
<h2 id="ddim">DDIM</h2>
<p>DDPM中，前向扩散过程定义为马尔科夫过程，为数据 <span class="math inline"><em>x</em><sub>0</sub></span> 逐步添加噪声，逆向过程同样需要逐步去噪。但是为了保证最终前向过程的 <span class="math inline"><em>x</em><sub><em>T</em></sub></span> 满足高斯噪声，这里的步数 <span class="math inline"><em>T</em></span> 要设置得足够大（1000+），导致逆向过程的采样步数也非常大，推理的时间和计算开销巨大。DDIM<sub><span style="color:blue;"><span class="citation" data-cites="song2020denoising">[@song2020denoising]</span></span></sub>提出了确定性采样方法，是扩散过程变为确定性过程（ODE），从而加速采样。</p>
<p>首先回顾一下定义在马尔科夫链的DDPM中单步加噪和单步去噪过程：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
        x_t &amp;= \sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t \\
        x_{t-1}&amp;=\frac{1}{\alpha_t}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha_t}}}\epsilon_\theta(x_t,t))+\sigma_t z
\end{split}
\end{gather}
$$</span></p>
<p>基于此重新推导DDPM的优化目标，可以得到：</p>
<p><span class="math display">$$ 
\begin{split}
\mathcal L=\mathbb{E}_{x_0,\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})}\left[\|\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon,t\right)\|^2\right] 
\end{split}
$$</span></p>
<p>可以发现，DDPM的优化目标其实仅仅依赖于边缘分布 <span class="math inline"><em>q</em>(<em>x</em><sub><em>t</em></sub>|<em>x</em><sub>0</sub>)</span> ，而不依赖于联合分布 <span class="math inline"><em>q</em>(<em>x</em><sub>1 : <em>T</em></sub>|<em>x</em><sub>0</sub>)</span> ，因此可以看出DDPM其实并不要求推理过程一定要是马尔科夫过程，只要推理分布满足边缘分布条件即可。经过一系列重新推导，可以得到非马尔科夫链下的单步逆向过程为：</p>
<p><span class="math display">$$
\begin{split}
\mathbf{x}_{t-1}=\sqrt{\alpha_{t-1}}\left(\underbrace{\frac{\mathbf{x}_t-\sqrt{1-\alpha_t}\epsilon_\theta(\mathbf{x}_t,t)}{\sqrt{\alpha_t}}}_{\mathrm{predicted~}\mathbf{x}_0}\right) +\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2}\cdot\epsilon_\theta(\mathbf{x}_t,t)}_{\text{direction pointing to }\mathbf{x}_t}+\underbrace{\sigma_t\epsilon_t}_{\text{random noise}}
\end{split}
$$</span></p>
<p>其中 <span class="math inline">$\sigma_t^2=\eta\cdot\sqrt{(1-\alpha_{t-1})/(1-\alpha_t)}\sqrt{(1-\alpha_t/\alpha_{t-1})}$</span> 。</p>
<ul>
<li>当 <span class="math inline"><em>η</em> = 1</span> 时，此时的生成过程和DDPM一致；</li>
<li>当 <span class="math inline"><em>η</em> = 0</span> 时，此时的生成过程就没有随机噪声项了，是一个确定性的过程，这就是DDIM（Denoising Diffusion Implic Model），此时的样本生成就变成了确定的过程，有点类似于SDE中的概率流ODE。</li>
</ul>
<figure>
<img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/DDIM_0.png" alt="" /><figcaption>DDIM的采样过程</figcaption>
</figure>
<p>由于DDIM并没有明确前向过程，这意味这可以定义一个更短的步数的前向过程以减少采样步数。原文从原始序列 <span class="math inline">[1, …, <em>T</em>]</span> 采样一个长度为 <span class="math inline"><em>S</em></span> 的子序列 <span class="math inline">[<em>τ</em><sub>1</sub>, …, <em>τ</em><sub><em>S</em></sub>]</span> ，此时前向过程 <span class="math inline">[<em>x</em><sub><em>τ</em><sub>1</sub></sub>, …, <em>x</em><sub><em>τ</em><sub><em>S</em></sub></sub>]</span> 同样满足 <span class="math inline">$q({x}_{\tau_i}|{x}_0)=\mathcal{N}({x}_t;\sqrt{\alpha_{\tau_i}}{x}_0,(1-\alpha_{\tau_i}){I})$</span> 。由此该生成过程也可以用这个子序列进行采样，最终加速生成过程，能从DDPM的1000步采样减少为50步采样，大幅降低推理开销。</p>
<h2 id="cdm">CDM</h2>
<p>条件扩散模型（Conditional Diffusion Model，CDM）指使用条件控制生成的扩散模型，其中最常用的方法是引导（guidance）方法，可以用于增强生成质量或是让模型朝向某个目标分布进行采样。最主要的两种方法是：分类器引导（Classifier Guidance）<sub><span style="color:blue;"><span class="citation" data-cites="dhariwal2021diffusion">[@dhariwal2021diffusion]</span></span></sub>和无分类器引导（Classifier-Free Guidance）<sub><span style="color:blue;"><span class="citation" data-cites="ho2022classifier">[@ho2022classifier]</span></span></sub>，因此这里将分别简要介绍这两篇工作。</p>
<h3 id="分类器引导">分类器引导</h3>
<p>假设我们需要在扩散过程中引入条件信息 <span class="math inline"><em>y</em></span> ，直觉上来说，条件信息不会影响前向过程，因为最终加噪都会变为高斯噪音，即 <span class="math inline"><em>q</em>(<em>x</em><sub>1 : <em>T</em></sub>|<em>x</em><sub>0</sub>, <em>y</em>) = <em>q</em>(<em>x</em><sub>1 : <em>T</em></sub>|<em>x</em><sub>0</sub>)</span> 。因此我们需要重点关注逆向过程的条件控制，不妨说我们需要重点关注分数函数 <span class="math inline"><em>ŝ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>, <em>t</em>) ≈ ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>)</span> 的变化。引入条件信息后，我们可以使用贝叶斯公式进行几步变换：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
        \nabla_{x_t}\log p(x_t|y)&amp;=\nabla_{x_t}\log(\frac{p(x_t)p(y|x_t)}{p(y)}) \\
        &amp;= \nabla_{x_t}\log p(x_t)+\nabla_{x_t}\log p(y|x_t)-\nabla_{x_t}\log p(y) \\ 
        &amp;= \nabla_{x_t}\log p(x_t)+\nabla_{x_t}\log p(y|x_t)
\end{split}
\end{gather}
$$</span></p>
<p>可以看到，展开后有两项，其中第一项相当于无条件生成时的分数函数，可以称为无条件分数（Unconditional Score）；而第二项相当于一个分类器的对数梯度，称为对抗梯度（Adversarial Gradient）。为了能更好的控制生成内容的方向，论文额外引入了一个超参数 <span class="math inline"><em>λ</em></span> 作为引导强度：</p>
<p><span class="math display">$$
\begin{gather}
\nabla_{x_t}\log p(x_t|y)=\nabla_{x_t}\log p(x_t)+\lambda\nabla_{x_t}\log p(y|x_t)
\end{gather}
$$</span></p>
<h3 id="无分类器引导">无分类器引导</h3>
<p>自OpenAI发布分类器引导的条件生成范式后，GoogleBrain团队提出了无分类器引导方法，直接在扩散模型内部学习引导信息，无需额外的分类器。还是从分数估计的角度来进行推导，从条件引导的工作我们得知 <span class="math inline">∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>|<em>y</em>) = ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>) + ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>y</em>|<em>x</em><sub><em>t</em></sub>)</span> ，变换一下可以得到 <span class="math inline">∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>y</em>|<em>x</em><sub><em>t</em></sub>) = ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>|<em>y</em>) − ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>p</em>(<em>x</em><sub><em>t</em></sub>)</span> ，由此可以得到：</p>
<p><span class="math display">$$
\begin{gather}
\begin{split}
    \nabla_{x_t}\log p(x_t|y)&amp;=\nabla_{x_t}\log p(x_t)+\lambda\nabla_{x_t}\log p(y|x_t) \\
    &amp;=\nabla_{x_t}\log p(x_t)+\lambda(\nabla_{x_t}\log p(x_t|y)-\nabla_{x_t}\log p(x_t)) \\
    &amp;=\lambda\nabla_{x_t}\log p(x_t|y)+(1-\lambda)\log p(x_t)
\end{split}
\end{gather}
$$</span></p>
<p>可以发现，此时分数仍然分为两部分：第一项可以看作是条件分数（Conditional Score），第二项则是无条件分数（Unconditional Score）。并且 <span class="math inline"><em>λ</em></span> 的取值会影响到条件控制的强弱：</p>
<ul>
<li>当 <span class="math inline"><em>λ</em> = 0</span> 时，此时相当于无条件生成；</li>
<li>当 <span class="math inline"><em>λ</em> &gt; 1</span> 时，模型会优先考虑条件控制而远离无条件分数网络方向。</li>
</ul>
<p>这样看似乎还是要训练两个网络，但实际上无条件可看作是条件控制的特殊情况，即 <span class="math inline"><em>y</em> = ⌀</span> ，这样在训练时可以交替训练有条件和无条件的情况。</p>
<h2 id="ldm">LDM</h2>
<p>DDPM生成的图像质量已经非常好了，但是训练开销很大，一个问题在于中间的加噪状态 <span class="math inline"><em>x</em><sub><em>t</em></sub></span> 的尺寸是和输入保持一致的，这使得其训练开销随图像分辨率的增大而加重，无法适应高质量图像生成任务。因此潜在扩散模型（Latent Diffusion Model，LDM）<sub><span style="color:blue;"><span class="citation" data-cites="rombach2022high">[@rombach2022high]</span></span></sub>针对这个问题做了一些改进，<strong>将图像从像素空间表示（Pixel Space）转变为潜在空间表示（Latent Space）实现高分辨率图像生成任务</strong>。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/LDM_0.png" alt="" /><figcaption>潜在扩散模型的模型架构</figcaption>
</figure>
<p>LDM的主要架构由三部分组成：VAE编码器（Encoder）、扩散模型以及VAE解码器（Decoder）。其中VAE编码器将高维图像 <span class="math inline"><em>x</em><sub>0</sub></span> 编码表示为潜在表示 <span class="math inline"><em>z</em><sub>0</sub></span> ，然后送入扩散模型中进行扩散和去噪，最终VAE解码器将去噪得到的潜在空间表示 <span class="math inline">$\hat{z_0}$</span> 还原为像素空间表示 <span class="math inline">$\hat{x_0}$</span> ，得到高质量的图像。这个VAE可以是预训练好的模型，在训练扩散模型时，其参数是被冻结的。</p>
<p>而对于条件生成处理上，LDM引入条件融合模块 <span class="math inline"><em>τ</em><sub><em>θ</em></sub></span> 来处理多种模态的条件信息 <span class="math inline"><em>y</em></span> 。比如对于文生图任务，这里的 <span class="math inline"><em>τ</em><sub><em>θ</em></sub></span> 就是一个文本编码器，可以使用预训练好的CLIP模型<sub><span style="color:blue;"><span class="citation" data-cites="radford2021learning">[@radford2021learning]</span></span></sub>中的文本编码器。同时引入条件融合开关：</p>
<ul>
<li>对于文本输入，这里在Unet网络中添加了Attention层将Embedding向量 <span class="math inline"><em>τ</em><sub><em>θ</em></sub>(<em>y</em>)</span> 融合到每层特征中；</li>
<li>而对于其他空间的条件（语义图、修复图等），则直接通过拼接完成条件融合。</li>
</ul>
<p>由此我们可以得到LDM的目标函数为：</p>
<p><span class="math display">$$
\begin{split}
\mathcal L_{L D M}:=\mathbb{E}_{\mathcal{E}(x), y, \epsilon \sim \mathcal{N}(0,1), t}\left[\left\|\epsilon-\epsilon_\theta\left(z_t, t, \tau_\theta(y)\right)\right\|_2^2\right]
\end{split}
$$</span></p>
<p>后续爆火的Stable Diffusion就是LDM的一个开源预训练模型，一度占据图像生成开源领域的主导地位。</p>
<h2 id="dit">DiT</h2>
<p>DiT（Diffusion Transformer）<sub><span style="color:blue;"><span class="citation" data-cites="peebles2023scalable">[@peebles2023scalable]</span></span></sub>是Meta AI提出的基于Transformer的扩散模型，它首次在扩散模型完全用Transformer替代了UNet，提升了扩散模型的可扩展性和生成质量。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/DiT_0.png" alt="" /><figcaption>DiT的模型架构</figcaption>
</figure>
<p>DiT也是一个作用在潜在空间上的模型，同样使用一个VQVAE将图像编码到潜在空间上，之后送入DiT模块中加工。不同的是，由于舍弃掉了CNN，这里使用了ViT进一步将潜在空间特征转换为一维序列特征（Patch Token），并将时间步 <span class="math inline"><em>t</em></span> 和条件信息 <span class="math inline"><em>y</em></span> 融合后嵌入到图像的Patch Token中。</p>
<p>为了选择融合条件特征效果最好的DiT模块，原文一共探索了四种不同的DiT模块：</p>
<ul>
<li>基于上下文条件（In-context conditioning）的DiT模块，直接将条件特征嵌入到输入序列中；</li>
<li>基于交叉注意力（Cross Attention）的DiT模块，将时间步 <span class="math inline"><em>t</em></span> 和条件信息 <span class="math inline"><em>y</em></span> 拼成长度为2的序列，然后输入到多头交叉注意力模块中和图像特征进行融合；</li>
<li>基于自适应层归一化（Adaptive Layer Normalization，AdaLN）的DiT模块，通过使用条件信息学习 <span class="math inline"><em>β</em></span> 和 <span class="math inline"><em>γ</em></span> 两个归一化参数来调整中间特征；</li>
<li>基于Zero初始化的AdaLN的DiT模块，是AdaLN方案的改进版本，将AdaLN的线性层参数初始化为zero，并额外在每个残差模块结束之前引入回归缩放参数 <span class="math inline"><em>α</em></span> 。</li>
</ul>
<p>通过对四种模块进行对比实验，发现AdaLN-Zero的效果是最好的，DiT模块默认采用这种方式来嵌入条件。</p>
<p>同时，需要注意的是DiT所使用的扩散模型沿用了OpenAI的改进版DDPM<sub><span style="color:blue;"><span class="citation" data-cites="song2020improved">[@song2020improved]</span></span></sub>，不再采用固定的方差，而是采用另一个网络来预测方差 <span class="math inline"><em>Σ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>) = exp (<em>v</em>log<em>β</em><sub><em>t</em></sub>+(1−<em>v</em>)<em>β̃</em><sub><em>t</em></sub>)</span> ，训练时采用无分类器引导的范式进行学习。该种方法对于视频生成等需要强可扩展性的任务来说很适用，OpenAI推出的Sora就是用了DiT作为模型架构。</p>
<h2 id="pixart">PixArt</h2>
<p>在DiT推出之后，华为诺亚方舟实验室又提出了PixArt-<span class="math inline"><em>α</em></span><sub><span style="color:blue;"><span class="citation" data-cites="chen2023pixart">[@chen2023pixart]</span></span></sub>，这也是一种基于transformer的文本到图像的扩散模型，它在显著降低训练成本的同时，也实现了很不错的图像生成质量。</p>
<p>PixArt-<span class="math inline"><em>α</em></span>模型还是使用DiT作为基础架构，但是进行了一些改进。原DiT架构中的每个DiT模块中的<span class="math inline"><em>S</em><sup><em>i</em></sup></span>都是通过独立的MLP计算得到的，即 <span class="math inline"><em>S</em><sup>(<em>i</em>)</sup> = <em>f</em><sup>(<em>i</em>)</sup>(<em>c</em> + <em>t</em>)</span> ，其中 <span class="math inline"><em>c</em>, <em>t</em></span> 分别表示类别条件和时间步信息，这会占据很高的开销。基于此，PixArt提出了AdaLN-single，定义一个全局 <span class="math inline"><em>S̄</em> = <em>f</em>(<em>t</em>)</span> ，只使用时间步信息生成 <span class="math inline"><em>S̄</em></span> ，在第 <span class="math inline"><em>i</em></span> 个模块中，通过计算 <span class="math inline"><em>S</em><sup>(<em>i</em>)</sup> = <em>g</em>(<em>S̄</em>, <em>E</em><sup>(<em>i</em>)</sup>)</span> 得到每个模块的缩放和偏移参数，其中 <span class="math inline"><em>E</em><sup>(<em>i</em>)</sup></span> 是可训练的嵌入表示；而文本条件 <span class="math inline"><em>c</em></span> 则通过一个额外的多头交叉注意力嵌入到模块中。大量实验表明，通过引入全局MLP和逐层嵌入处理时间步 <span class="math inline"><em>t</em></span> 信息、使用交叉注意力层处理文本信息 <span class="math inline"><em>c</em></span> 的改进，能在有效减小模型大小的同时保持原生成能力。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/PixArt_0.png" alt="" /><figcaption>PixArt-<span class="math inline"><em>α</em></span>的模型架构</figcaption>
</figure>
<p>除此之外，PixArt-<span class="math inline"><em>α</em></span>将复杂的文本到图像的生成任务分解为三个子任务以逐步训练：</p>
<ul>
<li>像素级依赖的学习（Pixel Dependency Learning），为了实现后续高质量的生成，PixArt先在ImageNet上预训练类引导生成模型，这一过程成本低廉并能帮助模型有效学习到图像的像素级依赖性；</li>
<li>文本到图像的精确对齐学习（Text-image Alignment Learning），原论文构建了一个包含高概念密度的精确文本-图像对数据集，相较于以往的数据集，歧义显著减少，并能处理更多的名词；</li>
<li>高质量图像微调（High-resolution and Aesthetic Image Generation），为了生成高审美质量的图片，原论文最后使用高质量的图片对模型进行进一步微调。</li>
</ul>
<h1 id="总结与展望">总结与展望</h1>
<p>在扩散模型成为主流之前，基于能量的生成模型和分数匹配已经被研究了许多年，这些工作为扩散模型的出现奠定了理论基础，直到后来DDPM的提出正式标志着扩散模型的爆发。之后一系列的工作探讨了对原始模型的改进，体现在加速采样、降低训练开销、提升图像生成质量等，一度使扩散模型超越基于自回归和GAN的生成模型成为大规模生成任务的首选模型。后来进入大模型时代，包括DALL·E、IMAGEN、Stable Diffusion的文生图大模型更是进一步引爆了Diffusion的影响力。总的来说，作为当下Aigc领域中热门研究领域之一，扩散模型的发展正值草长莺飞的时期，它开创了一种全新的生成模型范式，并被广泛应用于各类生成式任务以及当下视觉生成大模型中。</p>
<p>未来对于扩散模型的研究还在继续，比如如何进一步提升采样速度、创造更通用的多模态扩散模型、更精细的条件控制、量化优化以实现Edge AI等等，还有很多课题值得探索...</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://litchi-lee.github.io">Leo Sinclair</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://litchi-lee.github.io/2025/03/28/AIGC/overview_DM/">https://litchi-lee.github.io/2025/03/28/AIGC/overview_DM/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://litchi-lee.github.io" target="_blank">Leo的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AIGC/">AIGC</a></div><div class="post-share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg7.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/03/27/hello-world/" title="建站日志以及记录"><img class="cover" src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg5.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">建站日志以及记录</div></div><div class="info-2"><div class="info-item-1">小破站的一些修修补补日志，其实也不知道什么时候会断更:<</div></div></div></a><a class="pagination-related" href="/2025/04/15/AIGC/DDPM/" title="DDPM总结"><img class="cover" src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg8.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">DDPM总结</div></div><div class="info-2"><div class="info-item-1">主要扒一下DDPM的关键源码</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/04/17/AIGC/DDIM/" title="DDIM总结"><img class="cover" src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg8.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-17</div><div class="info-item-2">DDIM总结</div></div><div class="info-2"><div class="info-item-1">一些关于DDIM的总结，扒一下源码</div></div></div></a><a class="pagination-related" href="/2025/09/23/AIGC/DPM-Solver/" title="DPM-Solver和DPM-Solver++"><img class="cover" src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg5.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-23</div><div class="info-item-2">DPM-Solver和DPM-Solver++</div></div><div class="info-2"><div class="info-item-1">DPM-Solver和DPM-Solver++的介绍和如何应用</div></div></div></a><a class="pagination-related" href="/2025/04/15/AIGC/DDPM/" title="DDPM总结"><img class="cover" src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg8.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-15</div><div class="info-item-2">DDPM总结</div></div><div class="info-2"><div class="info-item-1">主要扒一下DDPM的关键源码</div></div></div></a><a class="pagination-related" href="/2025/05/08/AIGC/DIT/" title="DiT的细节"><img class="cover" src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg9.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-08</div><div class="info-item-2">DiT的细节</div></div><div class="info-2"><div class="info-item-1">一些细节记录</div></div></div></a><a class="pagination-related" href="/2025/05/20/AIGC/MAR/" title="MAR的细节"><img class="cover" src="/img/bg1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-20</div><div class="info-item-2">MAR的细节</div></div><div class="info-2"><div class="info-item-1">一些细节记录</div></div></div></a><a class="pagination-related" href="/2025/04/27/AIGC/LDM/" title="LDM的细节"><img class="cover" src="/img/bg1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-27</div><div class="info-item-2">LDM的细节</div></div><div class="info-2"><div class="info-item-1">一些细节记录</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/img0.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Leo Sinclair</div><div class="author-info-description">玻璃晴朗，橘子辉煌</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/litchi-lee"><i class="fab fa-github"></i><span>Follow</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/litchi-lee" target="_blank" title="GitHub"><i class="fab fa-github" style="color: #000000;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">warning：博主精神状态待观察</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-text">引言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">图像生成模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95"><span class="toc-text">扩散模型的发展</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text">相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ncsn"><span class="toc-text">NCSN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ddpm"><span class="toc-text">DDPM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E6%89%A9%E6%95%A3"><span class="toc-text">前向扩散</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%86%E5%90%91%E5%8E%BB%E5%99%AA"><span class="toc-text">逆向去噪</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sde"><span class="toc-text">SDE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ddim"><span class="toc-text">DDIM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cdm"><span class="toc-text">CDM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%99%A8%E5%BC%95%E5%AF%BC"><span class="toc-text">分类器引导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E5%88%86%E7%B1%BB%E5%99%A8%E5%BC%95%E5%AF%BC"><span class="toc-text">无分类器引导</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ldm"><span class="toc-text">LDM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dit"><span class="toc-text">DiT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pixart"><span class="toc-text">PixArt</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B"><span class="toc-text">总结与展望</span></a></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/05/08/AIGC/DIT/" title="DiT的细节"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DiT的细节"></a><div class="content"><a class="title" href="/2025/05/08/AIGC/DIT/" title="DiT的细节">DiT的细节</a><time datetime="2025-05-07T16:00:00.000Z" title="发表于 2025-05-08 00:00:00">2025-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/05/08/AIGC/iDDPM/" title="iDDPM总结"><img src="/img/bg4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="iDDPM总结"></a><div class="content"><a class="title" href="/2025/05/08/AIGC/iDDPM/" title="iDDPM总结">iDDPM总结</a><time datetime="2025-05-07T16:00:00.000Z" title="发表于 2025-05-08 00:00:00">2025-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/27/AIGC/LDM/" title="LDM的细节"><img src="/img/bg1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LDM的细节"></a><div class="content"><a class="title" href="/2025/04/27/AIGC/LDM/" title="LDM的细节">LDM的细节</a><time datetime="2025-04-26T16:00:00.000Z" title="发表于 2025-04-27 00:00:00">2025-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/17/AIGC/DDIM/" title="DDIM总结"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DDIM总结"></a><div class="content"><a class="title" href="/2025/04/17/AIGC/DDIM/" title="DDIM总结">DDIM总结</a><time datetime="2025-04-16T16:00:00.000Z" title="发表于 2025-04-17 00:00:00">2025-04-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/15/AIGC/DDPM/" title="DDPM总结"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DDPM总结"></a><div class="content"><a class="title" href="/2025/04/15/AIGC/DDPM/" title="DDPM总结">DDPM总结</a><time datetime="2025-04-14T16:00:00.000Z" title="发表于 2025-04-15 00:00:00">2025-04-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/28/AIGC/overview_DM/" title="扩散模型的发展（简略版）"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="扩散模型的发展（简略版）"></a><div class="content"><a class="title" href="/2025/03/28/AIGC/overview_DM/" title="扩散模型的发展（简略版）">扩散模型的发展（简略版）</a><time datetime="2025-03-27T16:00:00.000Z" title="发表于 2025-03-28 00:00:00">2025-03-28</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/23/AIGC/DPM-Solver/" title="DPM-Solver和DPM-Solver++"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DPM-Solver和DPM-Solver++"/></a><div class="content"><a class="title" href="/2025/09/23/AIGC/DPM-Solver/" title="DPM-Solver和DPM-Solver++">DPM-Solver和DPM-Solver++</a><time datetime="2025-09-22T16:00:00.000Z" title="发表于 2025-09-23 00:00:00">2025-09-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/22/Algo/dp/" title="动态规划"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="动态规划"/></a><div class="content"><a class="title" href="/2025/09/22/Algo/dp/" title="动态规划">动态规划</a><time datetime="2025-09-21T16:00:00.000Z" title="发表于 2025-09-22 00:00:00">2025-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/21/Algo/two_pointer/" title="双指针的使用"><img src="/img/bg1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="双指针的使用"/></a><div class="content"><a class="title" href="/2025/09/21/Algo/two_pointer/" title="双指针的使用">双指针的使用</a><time datetime="2025-09-20T16:00:00.000Z" title="发表于 2025-09-21 00:00:00">2025-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/19/Algo/cpp_use/" title="C++常用STL结构体"><img src="https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/bg9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C++常用STL结构体"/></a><div class="content"><a class="title" href="/2025/09/19/Algo/cpp_use/" title="C++常用STL结构体">C++常用STL结构体</a><time datetime="2025-09-18T16:00:00.000Z" title="发表于 2025-09-19 00:00:00">2025-09-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/22/AI/RLHF/" title="关于RLHF的一些学习记录"><img src="/img/bg4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="关于RLHF的一些学习记录"/></a><div class="content"><a class="title" href="/2025/08/22/AI/RLHF/" title="关于RLHF的一些学习记录">关于RLHF的一些学习记录</a><time datetime="2025-08-21T16:00:00.000Z" title="发表于 2025-08-22 00:00:00">2025-08-22</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/img2.png);"><div id="footer-wrap"><div class="copyright">&copy;2025 By Leo Sinclair</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><div class="footer_custom_text">In case I don't see you, good morning, good afternoon, and good night.</div></div><!-- APlayer 容器--><div id="aplayer"></div><!-- APlayer 初始化脚本--><script>const ap = new APlayer({
  container: document.getElementById('aplayer'),
  fixed: true,        // 固定在底部
  autoplay: true,     // 自动播放（注意浏览器可能会拦截）
  order: 'random',    // 随机播放
  loop: 'all',        // 循环播放
  preload: 'metadata',
  volume: 0.7,
  audio: [
    {
      name: 'L\'amore Dice Ciao',
      artist: 'Armando Trovajoli',
      url: 'music/audio1.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover1.png'
    },
    {
      name: 'Gymnopedie No.1',
      artist: 'Erik Satie',
      url: 'music/audio2.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover2.png'
    },
    {
      name: 'Ladyfingers Lofi',
      artist: 'Max Riser',
      url: 'music/audio3.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover3.png'
    },
    {
      name: 'Lujon',
      artist: 'Henry Mancini',
      url: 'music/audio4.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover4.png'
    },
    {
      name: 'Green Bird',
      artist: '菅野よう子',
      url: 'music/audio5.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover5.png'
    },
    {
      name: 'Change of Seasons',
      artist: 'Tokyo Music Walker',
      url: 'music/audio6.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover6.png'
    },
    {
      name: 'L\'hawaïenne',
      artist: 'La Femme',
      url: 'music/audio7.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover7.png'
    },
    {
      name: 'パッション･フラワー',
      artist: '細野晴臣/鈴木茂/山下達郎',
      url: 'music/audio8.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover8.png'
    },
    {
      name: '半城夏味',
      artist: '张斯函',
      url: 'music/audio9.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover9.png'
    },
    {
      name: 'Snowfall',
      artist: 'Tsundere Twintails',
      url: 'music/audio10.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover10.png'
    },
    {
      name: 'Simply Satie',
      artist: 'Michael Dulin',
      url: 'music/audio11.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover11.png'
    },
    {
      name: 'Gymnopédie no. 1',
      artist: 'Romi Kopelman',
      url: 'music/audio12.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover12.png'
    },
    {
      name: 'New Look',
      artist: 'Secret Potion/Lofi Beats To Chill Study Sleep',
      url: 'music/audio0.mp3',
      cover: 'https://cdn.jsdelivr.net/gh/litchi-lee/Images_shop@main/images/audio_cover3.png'
    }
  ]
});</script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>